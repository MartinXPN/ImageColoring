{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import threading\n",
    "from PIL import Image\n",
    "from skimage import io, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import Lambda\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from slice import Slice\n",
    "from colorizer import create_colorizer\n",
    "from discriminator import create_discriminator\n",
    "\n",
    "\n",
    "# We need only the conv part of VGG\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "image_mean = (103.939, 116.779, 123.68)\n",
    "greyscale_image_mean = np.mean(image_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(layers, is_trainable):\n",
    "    for l in layers:\n",
    "        l.trainable = is_trainable\n",
    "        \n",
    "def create_GAN(generator, discriminator):\n",
    "    generator_trainable_layers = [layer for layer in generator.layers if layer.trainable]\n",
    "    discriminator_trainable_layers = [layer for layer in discriminator.layers if layer.trainable]\n",
    "\n",
    "    network_input = Input(shape=(224, 224, 3))\n",
    "    generator_output = generator(network_input)\n",
    "\n",
    "    lightness = Slice(slice(0, 1), axis=3) (network_input)\n",
    "    lab = concatenate([lightness, generator_output])\n",
    "    network_output = discriminator(lab)\n",
    "\n",
    "    GAN = Model(network_input, network_output)\n",
    "    return GAN, generator_trainable_layers, discriminator_trainable_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colorizer, vgg = create_colorizer()\n",
    "discriminator = create_discriminator()\n",
    "gan, generator_trainable_layers, discriminator_trainable_layers = create_GAN(colorizer, discriminator)\n",
    "\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer='sgd')\n",
    "gan.compile(loss='binary_crossentropy', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = load_img('./dog.jpg', target_size=(224, 224))\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# res_first = first.predict([x], 1, verbose=1)\n",
    "res_second = colorizer.predict([x], 1, verbose=1)\n",
    "\n",
    "# print(res_first[0].shape)\n",
    "print(res_second[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "\n",
    "    def __init__(self, image_paths, batch_size, image_height, image_width, shuffle = True):\n",
    "        self.image_paths = image_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.generate_for_discriminator = True\n",
    "        self.lock = threading.Lock()\n",
    "        self.index = 0\n",
    "        if shuffle:\n",
    "            random.shuffle(self.image_paths)\n",
    "\n",
    "    def next(self, is_real):\n",
    "        with self.lock:\n",
    "            batch_features = np.zeros((self.batch_size, self.image_height, self.image_width, 3))\n",
    "            batch_labels   = np.zeros((self.batch_size))\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                path = self.image_paths[self.index]\n",
    "                \n",
    "                if self.generate_for_discriminator:\n",
    "                    image_gray = load_img(path, grayscale=True, target_size=(self.image_height, self.image_width))\n",
    "                    batch_features[i,:,:,0] = image_gray - greyscale_image_mean\n",
    "                    batch_features[i,:,:,1] = image_gray - greyscale_image_mean\n",
    "                    batch_features[i,:,:,2] = image_gray - greyscale_image_mean\n",
    "                    batch_labels[i] = is_real\n",
    "                else:\n",
    "                    image = io.imread(path)\n",
    "                    image = resize(image, output_shape=(self.image_height, self.image_width, 3))\n",
    "                    image_gray = load_img(path, grayscale=True, target_size=(self.image_height, self.image_width))\n",
    "                    batch_features[i] = color.rgb2lab(image)\n",
    "                    batch_features[i,:,:,0] = image_gray - greyscale_image_mean\n",
    "                    batch_labels[i] = is_real\n",
    "\n",
    "                self.index += 1\n",
    "                if self.index >= len(self.image_paths):\n",
    "                    self.index = 0\n",
    "            \n",
    "            return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define paths for train / validation / test datasets\n",
    "train_root = '../coco/train2014/'\n",
    "valid_root = '../coco/val2014/'\n",
    "test_root = '../coco/test2014/'\n",
    "\n",
    "train_image_paths = [train_root + item for item in os.listdir(train_root) if item.endswith('.jpg') ]\n",
    "valid_image_paths = [valid_root + item for item in os.listdir(valid_root) if item.endswith('.jpg') ]\n",
    "test_image_paths = [test_root + item for item in os.listdir(test_root) if item.endswith('.jpg') ]\n",
    "\n",
    "print( 'Train:', len(train_image_paths) )\n",
    "print( 'Validation:', len(valid_image_paths) )\n",
    "print( 'Test:', len(test_image_paths) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 37\n",
    "train_data_generator = BatchGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "valid_data_generator = BatchGenerator(image_paths=valid_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "\n",
    "print('There are', len(train_image_paths) / batch_size, 'steps per one train epoch for one complete cycle')\n",
    "print('There are', len(valid_image_paths) / batch_size, 'steps per one validation epoch for one complete cycle')\n",
    "\n",
    "checkpoint_path=\"../checkpoints/model-{epoch:03d}-{loss:.4f}.model\"\n",
    "model_saver = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', save_best_only=True, mode='min')\n",
    "# tensorboard = TensorBoard(log_dir='/tmp/coloring/')\n",
    "\n",
    "\n",
    "epochs = 77\n",
    "steps_per_epoch = 500\n",
    "validation_steps = 33\n",
    "# callbacks = [tensorboard, model_saver]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "class PlotLosses(object):\n",
    "    def __init__(self, figsize=(8,6)):\n",
    "        self.fig, self.ax = plt.subplots(1,1)\n",
    "\n",
    "\n",
    "    def plot(self, fake_discriminator_loss, real_discriminator_loss, generator_loss):\n",
    "        fake_discriminator_loss = np.array(fake_discriminator_loss)\n",
    "        real_discriminator_loss = np.array(real_discriminator_loss)\n",
    "        generator_loss = np.array(generator_loss)\n",
    "        \n",
    "        fake_d = self.ax.plot(fake_discriminator_loss) \n",
    "        real_d = self.ax.plot(real_discriminator_loss)\n",
    "        gen = self.ax.plot(generator_loss)\n",
    "\n",
    "#         self.fig.legend((fake_d, real_d, gen), ('fake_D', 'real_D', 'Gen'), 'upper right')\n",
    "        self.fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "fake_discriminator_loss = []\n",
    "real_discriminator_loss = []\n",
    "generator_loss = []\n",
    "loss_visualizer = PlotLosses()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    steps = [0, 1, 2] * steps_per_epoch\n",
    "    t = trange( len(steps) )\n",
    "    for i in t:\n",
    "        step = steps[i]\n",
    "        \n",
    "        # Make discriminator better on predicting real images\n",
    "        if step == 0:\n",
    "            train_data_generator.generate_for_discriminator = True\n",
    "            net = discriminator                                   # Propagate the data only through discriminator\n",
    "            make_trainable(discriminator_trainable_layers, True)  # make discriminator layers trainable\n",
    "            make_trainable(generator_trainable_layers, False)     # we don't touch the generator\n",
    "            batch = train_data_generator.next(is_real=True)       # Images are real\n",
    "            net_loss = real_discriminator_loss\n",
    "                \n",
    "        # Make discriminator better on detecting fake images\n",
    "        elif step == 1:\n",
    "            train_data_generator.generate_for_discriminator = False\n",
    "            net = gan                                             # Propagate the data though the whole gan\n",
    "            make_trainable(discriminator_trainable_layers, True)  # Train the discriminator\n",
    "            make_trainable(generator_trainable_layers, False)     # But don't touch the generator as it's not his turn\n",
    "            batch = train_data_generator.next(is_real=False)      # Images are fake\n",
    "            net_loss = fake_discriminator_loss\n",
    "        \n",
    "        # Make colorizer better in fooling the discriminator\n",
    "        else:\n",
    "            train_data_generator.generate_for_discriminator = False\n",
    "            net = gan                                             # Propagate the data through the whole gan\n",
    "            make_trainable(discriminator_trainable_layers, False) # Don't train the discriminator when fooling it\n",
    "            make_trainable(generator_trainable_layers, True)      # Train only the generator\n",
    "            batch = train_data_generator.next(is_real=True)       # Lets fool the discriminator\n",
    "            net_loss = generator_loss\n",
    "\n",
    "        x, y = batch\n",
    "        loss = net.train_on_batch(x, y)\n",
    "        net_loss.append(loss)\n",
    "        \n",
    "        loss_visualizer.plot(fake_discriminator_loss, real_discriminator_loss, generator_loss)\n",
    "        # Display progress\n",
    "        t.set_description('Train batch %i' % i)\n",
    "        t.set_postfix(loss=loss, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('../checkpoints/model-000-730.5353.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './puma.jpg' # random.choice(test_image_paths)\n",
    "\n",
    "rgb = io.imread(path)\n",
    "rgb = resize(rgb, output_shape=(224, 224, 3))\n",
    "image_gray = load_img(path, grayscale=True, target_size=(224, 224))\n",
    "lab = color.rgb2lab(rgb)\n",
    "\n",
    "inp = np.zeros((224, 224, 3))\n",
    "inp[:,:,0] = image_gray - greyscale_image_mean\n",
    "inp[:,:,1] = image_gray - greyscale_image_mean\n",
    "inp[:,:,2] = image_gray - greyscale_image_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "out = model.predict(np.array([inp]), batch_size=1)[0]\n",
    "\n",
    "img = np.zeros((224, 224, 3))\n",
    "img[:,:,0] = lab[...,0]\n",
    "img[:,:,1:] = out\n",
    "\n",
    "plt.imshow(color.lab2rgb(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
