{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from keras.layers import *\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import *\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from skimage import io, color\n",
    "from skimage.transform import resize\n",
    "\n",
    "from util import make_trainable\n",
    "from batch_generators import DiscriminatorRealGenerator, ColorizerBatchGenerator, DiscriminatorFakeGenerator\n",
    "from models import create_colorizer, create_discriminator, create_GAN\n",
    "from visualizers import LossVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colorizer, vgg = create_colorizer()\n",
    "discriminator = create_discriminator()\n",
    "gan, generator_trainable_layers, discriminator_trainable_layers = create_GAN(colorizer, discriminator)\n",
    "\n",
    "discriminator.compile( loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.01, nesterov=True) )\n",
    "gan.compile( loss=['binary_crossentropy', 'mae'],  optimizer=SGD(lr=0.01, momentum=0.01, nesterov=True), loss_weights=[1.0, 5.0] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define paths for train / validation / test datasets\n",
    "train_root = '../coco/train2017/'\n",
    "train_image_paths = [train_root + item for item in os.listdir(train_root) if item.endswith('.jpg') ]\n",
    "print( 'Train:', len(train_image_paths) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 37\n",
    "\n",
    "# Train data generators\n",
    "discriminator_real_generator = DiscriminatorRealGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "discriminator_fake_generator = DiscriminatorFakeGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "colorizer_generator = ColorizerBatchGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "\n",
    "print('There are', len(train_image_paths) / batch_size, 'steps per one train epoch for one complete cycle')\n",
    "checkpoint_path=\"../checkpoints/model-{epoch:03d}-{loss:.4f}.model\"\n",
    "model_saver = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(log_dir='/tmp/coloring/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load models\n",
    "# discriminator = load_model('../checkpoints/discriminator-3.model')\n",
    "# colorizer = load_model('../checkpoints/colorizer-3.model')\n",
    "# gan = load_model('../checkpoints/gan-3.model', custom_objects={'Slice': Slice})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib notebook\n",
    "\n",
    "def last(arr, k=100):\n",
    "    if arr:  return arr[-1]\n",
    "    else:    return k\n",
    "\n",
    "\n",
    "fake_discriminator_loss = []\n",
    "real_discriminator_loss = []\n",
    "generator_loss = []\n",
    "\n",
    "epochs = 2\n",
    "steps_per_epoch = 500\n",
    "validation_steps = 33\n",
    "plot_frequency = 3\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    \n",
    "    t = tqdm(range(steps_per_epoch))\n",
    "    loss_visualizer = LossVisualizer()\n",
    "\n",
    "    for i in t:\n",
    "        latest_results = [last(real_discriminator_loss), last(fake_discriminator_loss), last(generator_loss)]\n",
    "        step = np.argmax(latest_results)\n",
    "        \n",
    "        # Make discriminator better on predicting real images\n",
    "        if step == 0:\n",
    "            net = discriminator                                   # Propagate the data only through discriminator\n",
    "            make_trainable(discriminator_trainable_layers, True)  # make discriminator layers trainable\n",
    "            make_trainable(generator_trainable_layers, False)     # we don't touch the generator\n",
    "            batch_generator = discriminator_real_generator        # Images are real\n",
    "            net_loss = real_discriminator_loss\n",
    "                \n",
    "        # Make discriminator better on detecting fake images\n",
    "        elif step == 1:\n",
    "            net = gan                                             # Propagate the data though the whole gan\n",
    "            make_trainable(discriminator_trainable_layers, True)  # Train the discriminator\n",
    "            make_trainable(generator_trainable_layers, False)     # But don't touch the generator as it's not his turn\n",
    "            batch_generator = discriminator_fake_generator        # Images are fake\n",
    "            net_loss = fake_discriminator_loss\n",
    "        \n",
    "        # Make colorizer better in fooling the discriminator\n",
    "        else:\n",
    "            net = gan                                             # Propagate the data through the whole gan\n",
    "            make_trainable(discriminator_trainable_layers, False) # Don't train the discriminator when fooling it\n",
    "            make_trainable(generator_trainable_layers, True)      # Train only the generator\n",
    "            batch_generator = colorizer_generator                 # Lets fool the discriminator\n",
    "            net_loss = generator_loss\n",
    "\n",
    "        \n",
    "        # Train on the current batch\n",
    "        batch = batch_generator.next()\n",
    "        if len(batch) == 2:\n",
    "            inputs, labels = batch\n",
    "            loss = net.train_on_batch(inputs, labels)\n",
    "        else:\n",
    "            inputs, labels, image_labels = batch\n",
    "            loss = net.train_on_batch(inputs, [labels, image_labels])[1]\n",
    "        net_loss.append(loss)\n",
    "        \n",
    "        \n",
    "        # Plot the loss graph\n",
    "        if i % plot_frequency == 0:\n",
    "            loss_visualizer.plot(fake_discriminator_loss, real_discriminator_loss, generator_loss)\n",
    "        \n",
    "        # Display progress\n",
    "        t.set_description('Train batch %i' % i)\n",
    "        t.set_postfix(loss=loss, step=step)\n",
    "    \n",
    "    # Save model checkpoints\n",
    "    gan.save('../checkpoints/gan-' + str(epoch) + '.model')\n",
    "    colorizer.save('../checkpoints/colorizer-' + str(epoch) + '.model')\n",
    "    discriminator.save('../checkpoints/discriminator-' + str(epoch) + '.model')\n",
    "    \n",
    "    # Clear loss lists to prepare for the next epoch\n",
    "    del fake_discriminator_loss[:]\n",
    "    del real_discriminator_loss[:]\n",
    "    del generator_loss[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "path = './puma.jpg'                                          # random.choice(test_image_paths)\n",
    "inp, _ = colorizer_generator.generate_one(path)              # get input for generator\n",
    "\n",
    "out = colorizer.predict(np.array([inp]), batch_size=1)[0]    # make a prediction and get a,b channels scaled to (-1;1)\n",
    "\n",
    "rgb = resize( io.imread(path), output_shape=(224, 224, 3) )  # resize the image to display it later on\n",
    "img = np.zeros((224, 224, 3))                                # image that we are displaying has 224x224 size\n",
    "img[...,0] = color.rgb2lab(rgb)[...,0]                       # first channel is the lightness of the image\n",
    "img[...,1:] = out * 128.                                     # a,b channels are scaled to [-128;128]\n",
    "\n",
    "print(out.shape)\n",
    "plt.imshow(color.lab2rgb(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(out)):\n",
    "    for j in out[i]:\n",
    "        if j[0] != j[1]:\n",
    "            print( j[0], j[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[77][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
