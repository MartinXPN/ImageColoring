{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import *\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from imagenet_utils import _obtain_input_shape\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "# We need only the conv part of VGG\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_tensor=None, input_shape=None):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=False)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        inputs = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            inputs = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            inputs = input_tensor\n",
    "    \n",
    "    # Encoder 1\n",
    "    e11 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "    e12 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(e11)\n",
    "    e13 = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(e12)\n",
    "\n",
    "    # Encoder 2\n",
    "    e21 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(e13)\n",
    "    e22 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(e21)\n",
    "    e23 = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(e22)\n",
    "\n",
    "    # Encoder 3\n",
    "    e31 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(e23)\n",
    "    e32 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(e31)\n",
    "    e33 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(e32)\n",
    "    e34 = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(e33)\n",
    "\n",
    "    # Encoder 4\n",
    "    e41 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(e34)\n",
    "    e42 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(e41)\n",
    "    e43 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(e42)\n",
    "    e44 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(e43)\n",
    "\n",
    "    # Encoder 5\n",
    "    e51 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(e44)\n",
    "    e52 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(e51)\n",
    "    e53 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(e52)\n",
    "    e54 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(e53)\n",
    "    \n",
    "    # Now lets decode the representation\n",
    "    # Using residual connections (in this case concatenate)\n",
    "    \n",
    "    # Decoder 5\n",
    "    d51 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv1')(e54)\n",
    "    d52 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv2')(d51)\n",
    "    d53 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv3')(d52)\n",
    "    d54 = UpSampling2D((2, 2), name='block5_upsample')(d53)\n",
    "    \n",
    "    # Decoder 4\n",
    "    merged = concatenate([d54, e44])\n",
    "    d41 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv1')(merged)\n",
    "    d42 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv2')(d41)\n",
    "    d43 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv3')(d42)\n",
    "    d44 = UpSampling2D((2, 2), name='block4_upsample')(d43)\n",
    "    \n",
    "    # Decoder 3\n",
    "    merged = concatenate([d44, e34])\n",
    "    d31 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv1')(merged)\n",
    "    d32 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv2')(d31)\n",
    "    d33 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv3')(d32)\n",
    "    d34 = UpSampling2D((2, 2), name='block3_upsample')(d33)\n",
    "    \n",
    "    # Decoder 2\n",
    "    merged = concatenate([d34, e23])\n",
    "    d21 = Deconvolution2D(64, (3, 3), activation='relu', padding='same', name='block2_deconv1')(merged)\n",
    "    d22 = Deconvolution2D(64, (3, 3), activation='relu', padding='same', name='block2_deconv2')(d21)\n",
    "    d23 = UpSampling2D((2, 2), name='block2_upsample')(d22)\n",
    "    \n",
    "    # Decoder 1\n",
    "    merged = concatenate([d23, e13])\n",
    "    d11 = Deconvolution2D(32, (3, 3), activation='relu', padding='same', name='block1_deconv1')(merged)\n",
    "    d12 = Deconvolution2D(32, (3, 3), activation='relu', padding='same', name='block1_deconv2')(d11)\n",
    "    d13 = UpSampling2D((2, 2), name='block1_upsample')(d12)\n",
    "    \n",
    "    d01 = Conv2D(16, (3, 3), activation='relu',    padding='same', name='out1')(d13)\n",
    "    d02 = Conv2D(3, (3, 3), activation='sigmoid', padding='same', name='out2')(d01)\n",
    "\n",
    "\n",
    "    \n",
    "    # Create model.\n",
    "    vgg16 = Model(inputs, e54, name='vgg16')\n",
    "    weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                            WEIGHTS_PATH_NO_TOP,\n",
    "                            cache_subdir='models')\n",
    "    \n",
    "    # Load weights of vgg16 and fix them (set non-trainable)\n",
    "    vgg16.load_weights(weights_path)\n",
    "    for l in vgg16.layers:\n",
    "        l.trainable = False\n",
    "    \n",
    "    model = Model(inputs, d02, name='colorizer')\n",
    "    print( model.summary() )\n",
    "    return model, vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, vgg = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = load_img('./Shifen-Waterfall-Taiwan-1.png', target_size=(224, 224))\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# res_first = first.predict([x], 1, verbose=1)\n",
    "res_second = model.predict([x], 1, verbose=1)\n",
    "\n",
    "# print(res_first[0].shape)\n",
    "print(res_second[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='kullback_leibler_divergence', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "\n",
    "    def __init__(self, image_paths, batch_size, image_height, image_width, shuffle = True):\n",
    "        self.image_paths = image_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.lock = threading.Lock()\n",
    "        self.index = 0\n",
    "        if shuffle:\n",
    "            random.shuffle(self.image_paths)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            batch_features = np.zeros((self.batch_size, self.image_height, self.image_width, 3))\n",
    "            batch_labels   = np.zeros((self.batch_size, self.image_height, self.image_width, 3))\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                path = self.image_paths[self.index]\n",
    "                image = load_img(path, target_size=(self.image_height, self.image_width))\n",
    "                image_gray = image.convert('L')\n",
    "\n",
    "                batch_features[i,:,:,0] = image_gray\n",
    "                batch_features[i,:,:,1] = image_gray\n",
    "                batch_features[i,:,:,2] = image_gray\n",
    "                batch_labels[i] = load_img(path, target_size=(self.image_height, self.image_width))\n",
    "                \n",
    "                self.index += 1\n",
    "                if self.index >= len(self.image_paths):\n",
    "                    self.index = 0\n",
    "            return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define paths for train / validation / test datasets\n",
    "train_root = '../coco/train2014/'\n",
    "valid_root = '../coco/val2014/'\n",
    "test_root = '../coco/test2014/'\n",
    "\n",
    "train_image_paths = [train_root + item for item in os.listdir(train_root) if item.endswith('.jpg') ]\n",
    "valid_image_paths = [valid_root + item for item in os.listdir(valid_root) if item.endswith('.jpg') ]\n",
    "test_image_paths = [test_root + item for item in os.listdir(test_root) if item.endswith('.jpg') ]\n",
    "\n",
    "print( 'Train:', len(train_image_paths) )\n",
    "print( 'Validation:', len(valid_image_paths) )\n",
    "print( 'Test:', len(test_image_paths) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "train_data_generator = BatchGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "valid_data_generator = BatchGenerator(image_paths=valid_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "\n",
    "checkpoint_path=\"../checkpoints/model-{epoch:02d}-{loss:.4f}.model\"\n",
    "model_saver = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(log_dir='/tmp/coloring/')\n",
    "\n",
    "model.fit_generator(generator=train_data_generator, \n",
    "                    steps_per_epoch = len(train_image_paths) / batch_size, \n",
    "                    validation_data=valid_data_generator, \n",
    "                    validation_steps = len(valid_image_paths) / batch_size,\n",
    "                    callbacks=[tensorboard, model_saver], \n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path= random.choice(image_paths)\n",
    "image = load_img(path, target_size=(224, 224))\n",
    "image_gray = image.convert('L')\n",
    "\n",
    "inp = np.zeros((image.height, image.width, 3))\n",
    "inp[:,:,0] = image_gray\n",
    "inp[:,:,1] = image_gray\n",
    "inp[:,:,2] = image_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "out = model.predict(np.array([inp]), batch_size=1)\n",
    "img = Image.fromarray(out[0], 'RGB')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
