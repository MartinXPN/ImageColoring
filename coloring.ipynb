{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import threading\n",
    "from PIL import Image\n",
    "from skimage import io, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import Lambda\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "# We need only the conv part of VGG\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "image_mean = (103.939, 116.779, 123.68)\n",
    "greyscale_image_mean = np.mean(image_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_generator(input_shape=(None, None, 3)):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Encoder 1\n",
    "    e11 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "    e12 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(e11)\n",
    "    e13 = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(e12)\n",
    "\n",
    "    # Encoder 2\n",
    "    e21 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(e13)\n",
    "    e22 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(e21)\n",
    "    e23 = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(e22)\n",
    "\n",
    "    # Encoder 3\n",
    "    e31 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(e23)\n",
    "    e32 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(e31)\n",
    "    e33 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(e32)\n",
    "    e34 = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(e33)\n",
    "\n",
    "    # Encoder 4\n",
    "    e41 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(e34)\n",
    "    e42 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(e41)\n",
    "    e43 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(e42)\n",
    "    e44 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(e43)\n",
    "\n",
    "    # Encoder 5\n",
    "    e51 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(e44)\n",
    "    e52 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(e51)\n",
    "    e53 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(e52)\n",
    "    e54 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(e53)\n",
    "    \n",
    "    # *********************************************************************************** #\n",
    "    # Now lets decode the representation                                                  #\n",
    "    # Using residual connections (in this case concatenate)                               #\n",
    "    # *********************************************************************************** #\n",
    "\n",
    "    # Decoder 5\n",
    "    d51 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv1')(e54)\n",
    "    d52 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv2')(d51)\n",
    "    d53 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv3')(d52)\n",
    "    d54 = UpSampling2D((2, 2), name='block5_upsample')(d53)\n",
    "    \n",
    "    # Decoder 4\n",
    "    merged = concatenate([d54, e44])\n",
    "    d41 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv1')(merged)\n",
    "    d42 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv2')(d41)\n",
    "    d43 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv3')(d42)\n",
    "    d44 = UpSampling2D((2, 2), name='block4_upsample')(d43)\n",
    "    \n",
    "    # Decoder 3\n",
    "    merged = concatenate([d44, e34])\n",
    "    d31 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv1')(merged)\n",
    "    d32 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv2')(d31)\n",
    "    d33 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv3')(d32)\n",
    "    d34 = UpSampling2D((2, 2), name='block3_upsample')(d33)\n",
    "    \n",
    "    # Decoder 2\n",
    "    merged = concatenate([d34, e23])\n",
    "    d21 = Deconvolution2D(64, (3, 3), activation='relu', padding='same', name='block2_deconv1')(merged)\n",
    "    d22 = Deconvolution2D(64, (3, 3), activation='relu', padding='same', name='block2_deconv2')(d21)\n",
    "    d23 = UpSampling2D((2, 2), name='block2_upsample')(d22)\n",
    "    \n",
    "    # Decoder 1\n",
    "    merged = concatenate([d23, e13])\n",
    "    d11 = Deconvolution2D(32, (3, 3), activation='relu', padding='valid', name='block1_deconv1')(merged)\n",
    "    d12 = Deconvolution2D(32, (4, 4), strides=2, activation='relu', padding='valid', name='block1_deconv2')(d11)\n",
    "    \n",
    "    d01 = Conv2D(16, (3, 3), activation='relu',    padding='valid', name='out1')(d12)\n",
    "    d02 = Conv2D(2, (5, 5), activation='tanh', padding='valid', name='out2')(d01)\n",
    "    out = Lambda(lambda x: x * 128.) (d02) # Map sigmoid to [-128; 128]\n",
    "\n",
    "\n",
    "    \n",
    "    # Create model.\n",
    "    vgg16 = Model(inputs, e54, name='vgg16')\n",
    "    weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models')\n",
    "    \n",
    "    # Load weights of vgg16 and fix them (set non-trainable)\n",
    "    vgg16.load_weights(weights_path)\n",
    "    for l in vgg16.layers:\n",
    "        l.trainable = False\n",
    "    \n",
    "    model = Model(inputs, out, name='colorizer')\n",
    "    print( model.summary() )\n",
    "    return model, vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_discriminator(input_shape=(224, 224, 3)):\n",
    "    \n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    x = Flatten(name='flatten')(x)\n",
    "    x = Dense(1024, activation='relu', name='fc1')(x)\n",
    "    out = Dense(1, activation='sigmoid', name='out')(x)\n",
    "    \n",
    "    model = Model(inputs, out, name='discriminator')\n",
    "    print( model.summary() )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, vgg = create_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "discriminator = create_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = load_img('./dog.jpg', target_size=(224, 224))\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# res_first = first.predict([x], 1, verbose=1)\n",
    "res_second = model.predict([x], 1, verbose=1)\n",
    "\n",
    "# print(res_first[0].shape)\n",
    "print(res_second[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "\n",
    "    def __init__(self, image_paths, batch_size, image_height, image_width, shuffle = True):\n",
    "        self.image_paths = image_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.generate_for_discriminator = True\n",
    "        self.lock = threading.Lock()\n",
    "        self.index = 0\n",
    "        if shuffle:\n",
    "            random.shuffle(self.image_paths)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            self.generate_grayscale = bool( 1 - self.generate_grayscale )\n",
    "            batch_features = np.zeros((self.batch_size, self.image_height, self.image_width, 3))\n",
    "            batch_labels   = np.zeros((self.batch_size))\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                path = self.image_paths[self.index]\n",
    "                \n",
    "                if generate_for_discriminator:\n",
    "                    image_gray = load_img(path, grayscale=True, target_size=(self.image_height, self.image_width))\n",
    "                    batch_features[i,:,:,0] = image_gray - greyscale_image_mean\n",
    "                    batch_features[i,:,:,1] = image_gray - greyscale_image_mean\n",
    "                    batch_features[i,:,:,2] = image_gray - greyscale_image_mean\n",
    "                    batch_label[i] = 0 # Fake\n",
    "                else:\n",
    "                    image = io.imread(path)\n",
    "                    image = resize(image, output_shape=(self.image_height, self.image_width, 3))\n",
    "                    batch_features[i] = color.rgb2lab(image)\n",
    "                    batch_labels[i] = 1 # Real\n",
    "                                \n",
    "                self.index += 1\n",
    "                if self.index >= len(self.image_paths):\n",
    "                    self.index = 0\n",
    "            \n",
    "            return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define paths for train / validation / test datasets\n",
    "train_root = '../coco/train2014/'\n",
    "valid_root = '../coco/val2014/'\n",
    "test_root = '../coco/test2014/'\n",
    "\n",
    "train_image_paths = [train_root + item for item in os.listdir(train_root) if item.endswith('.jpg') ]\n",
    "valid_image_paths = [valid_root + item for item in os.listdir(valid_root) if item.endswith('.jpg') ]\n",
    "test_image_paths = [test_root + item for item in os.listdir(test_root) if item.endswith('.jpg') ]\n",
    "\n",
    "print( 'Train:', len(train_image_paths) )\n",
    "print( 'Validation:', len(valid_image_paths) )\n",
    "print( 'Test:', len(test_image_paths) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 37\n",
    "train_data_generator = BatchGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "valid_data_generator = BatchGenerator(image_paths=valid_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "\n",
    "print('There are', len(train_image_paths) / batch_size, 'steps per one train epoch for one complete cycle')\n",
    "print('There are', len(valid_image_paths) / batch_size, 'steps per one validation epoch for one complete cycle')\n",
    "\n",
    "checkpoint_path=\"../checkpoints/model-{epoch:03d}-{loss:.4f}.model\"\n",
    "model_saver = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', save_best_only=True, mode='min')\n",
    "tensorboard = TensorBoard(log_dir='/tmp/coloring/')\n",
    "\n",
    "model.fit_generator(generator=train_data_generator, \n",
    "                    steps_per_epoch = 500, # len(train_image_paths) / batch_size, \n",
    "                    validation_data=valid_data_generator, \n",
    "                    validation_steps = 33,\n",
    "                    epochs=77,\n",
    "                    callbacks=[tensorboard, model_saver],\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('../checkpoints/model-000-730.5353.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './puma.jpg' # random.choice(test_image_paths)\n",
    "\n",
    "rgb = io.imread(path)\n",
    "rgb = resize(rgb, output_shape=(224, 224, 3))\n",
    "image_gray = load_img(path, grayscale=True, target_size=(224, 224))\n",
    "lab = color.rgb2lab(rgb)\n",
    "\n",
    "inp = np.zeros((224, 224, 3))\n",
    "inp[:,:,0] = image_gray - greyscale_image_mean\n",
    "inp[:,:,1] = image_gray - greyscale_image_mean\n",
    "inp[:,:,2] = image_gray - greyscale_image_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(np.array([inp]), batch_size=1)[0]\n",
    "\n",
    "img = np.zeros((224, 224, 3))\n",
    "img[:,:,0] = lab[...,0]\n",
    "img[:,:,1:] = out\n",
    "\n",
    "plt.imshow(color.lab2rgb(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
