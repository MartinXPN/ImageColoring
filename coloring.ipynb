{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import threading\n",
    "from PIL import Image\n",
    "from skimage import io, color\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "import keras\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras.layers.core import Lambda\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from slice import Slice\n",
    "from colorizer import create_colorizer\n",
    "from discriminator import create_discriminator\n",
    "from batch_generators import DiscriminatorRealGenerator, ColorizerBatchGenerator, DiscriminatorFakeGenerator\n",
    "\n",
    "# We need only the conv part of VGG\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "image_mean = (103.939, 116.779, 123.68)\n",
    "greyscale_image_mean = np.mean(image_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(layers, is_trainable):\n",
    "    for l in layers:\n",
    "        l.trainable = is_trainable\n",
    "        \n",
    "def create_GAN(generator, discriminator):\n",
    "    generator_trainable_layers = [layer for layer in generator.layers if layer.trainable]\n",
    "    discriminator_trainable_layers = [layer for layer in discriminator.layers if layer.trainable]\n",
    "\n",
    "    network_input = Input(shape=(224, 224, 3))\n",
    "    generator_output = generator(network_input)\n",
    "\n",
    "    lightness = Slice(slice(0, 1), axis=3) (network_input)\n",
    "    lab = concatenate([lightness, generator_output])\n",
    "    network_output = discriminator(lab)\n",
    "\n",
    "    GAN = Model(network_input, network_output)\n",
    "    return GAN, generator_trainable_layers, discriminator_trainable_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colorizer, vgg = create_colorizer()\n",
    "discriminator = create_discriminator()\n",
    "gan, generator_trainable_layers, discriminator_trainable_layers = create_GAN(colorizer, discriminator)\n",
    "\n",
    "discriminator.compile( loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.01, nesterov=True) )\n",
    "gan.compile(           loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.01, nesterov=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = load_img('./dog.jpg', target_size=(224, 224))\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# res_first = first.predict([x], 1, verbose=1)\n",
    "res_second = colorizer.predict([x], 1, verbose=1)\n",
    "\n",
    "# print(res_first[0].shape)\n",
    "print(res_second[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define paths for train / validation / test datasets\n",
    "train_root = '../coco/train2014/'\n",
    "valid_root = '../coco/val2014/'\n",
    "test_root = '../coco/test2014/'\n",
    "\n",
    "train_image_paths = [train_root + item for item in os.listdir(train_root) if item.endswith('.jpg') ]\n",
    "valid_image_paths = [valid_root + item for item in os.listdir(valid_root) if item.endswith('.jpg') ]\n",
    "test_image_paths  = [test_root  + item for item in os.listdir(test_root)  if item.endswith('.jpg') ]\n",
    "\n",
    "print( 'Train:', len(train_image_paths) )\n",
    "print( 'Validation:', len(valid_image_paths) )\n",
    "print( 'Test:', len(test_image_paths) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 37\n",
    "\n",
    "# Train data generators\n",
    "discriminator_real_generator = DiscriminatorRealGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "discriminator_fake_generator = DiscriminatorFakeGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "colorizer_generator = ColorizerBatchGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "\n",
    "print('There are', len(train_image_paths) / batch_size, 'steps per one train epoch for one complete cycle')\n",
    "print('There are', len(valid_image_paths) / batch_size, 'steps per one validation epoch for one complete cycle')\n",
    "\n",
    "checkpoint_path=\"../checkpoints/model-{epoch:03d}-{loss:.4f}.model\"\n",
    "model_saver = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', save_best_only=True, mode='min')\n",
    "# tensorboard = TensorBoard(log_dir='/tmp/coloring/')\n",
    "\n",
    "\n",
    "epochs = 77\n",
    "steps_per_epoch = 500\n",
    "validation_steps = 33\n",
    "# callbacks = [tensorboard, model_saver]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class PlotLosses(object):\n",
    "    def __init__(self, figsize=(12,8), last_iterations=5):\n",
    "        self.fig, self.ax = plt.subplots(1,1)\n",
    "        self.last_iterations = last_iterations\n",
    "\n",
    "\n",
    "    def plot(self, fake_discriminator_loss, real_discriminator_loss, generator_loss):\n",
    "        maxlen = max( len(fake_discriminator_loss), len(real_discriminator_loss), len(generator_loss) )\n",
    "        while len(fake_discriminator_loss) < maxlen and fake_discriminator_loss: fake_discriminator_loss.append( fake_discriminator_loss[-1] )\n",
    "        while len(real_discriminator_loss) < maxlen and fake_discriminator_loss: real_discriminator_loss.append( real_discriminator_loss[-1] )\n",
    "        while len(generator_loss) < maxlen          and generator_loss:          generator_loss.append( generator_loss[-1] )\n",
    "            \n",
    "        fake_discriminator_loss = np.array(fake_discriminator_loss)\n",
    "        real_discriminator_loss = np.array(real_discriminator_loss)\n",
    "        generator_loss = np.array(generator_loss)\n",
    "        \n",
    "        fake_d = self.ax.plot(fake_discriminator_loss, color='red') \n",
    "        real_d = self.ax.plot(real_discriminator_loss, color='green')\n",
    "        gen = self.ax.plot(generator_loss, color='blue')\n",
    "\n",
    "#         self.fig.legend((fake_d, real_d, gen), ('fake_D', 'real_D', 'Gen'), 'upper right')\n",
    "        self.fig.canvas.draw()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "\n",
    "fake_discriminator_loss = []\n",
    "real_discriminator_loss = []\n",
    "generator_loss = []\n",
    "loss_visualizer = PlotLosses()\n",
    "pattern = [0, 2, 1, 2, 1, 2]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    steps = pattern * ( steps_per_epoch / len(pattern) )\n",
    "    t = tqdm( range(len(steps)) )\n",
    "    for i in t:\n",
    "        step = steps[i]\n",
    "        \n",
    "        # Make discriminator better on predicting real images\n",
    "        if step == 0:\n",
    "            net = discriminator                                   # Propagate the data only through discriminator\n",
    "            make_trainable(discriminator_trainable_layers, True)  # make discriminator layers trainable\n",
    "            make_trainable(generator_trainable_layers, False)     # we don't touch the generator\n",
    "            batch_generator = discriminator_real_generator        # Images are real\n",
    "            net_loss = real_discriminator_loss\n",
    "                \n",
    "        # Make discriminator better on detecting fake images\n",
    "        elif step == 1:\n",
    "            net = gan                                             # Propagate the data though the whole gan\n",
    "            make_trainable(discriminator_trainable_layers, True)  # Train the discriminator\n",
    "            make_trainable(generator_trainable_layers, False)     # But don't touch the generator as it's not his turn\n",
    "            batch_generator = discriminator_fake_generator        # Images are fake\n",
    "            net_loss = fake_discriminator_loss\n",
    "        \n",
    "        # Make colorizer better in fooling the discriminator\n",
    "        else:\n",
    "            net = gan                                             # Propagate the data through the whole gan\n",
    "            make_trainable(discriminator_trainable_layers, False) # Don't train the discriminator when fooling it\n",
    "            make_trainable(generator_trainable_layers, True)      # Train only the generator\n",
    "            batch_generator = colorizer_generator                 # Lets fool the discriminator\n",
    "            net_loss = generator_loss\n",
    "\n",
    "            \n",
    "        # Train on the current batch\n",
    "        batch = batch_generator.next()\n",
    "        x, y = batch\n",
    "        loss = net.train_on_batch(x, y)\n",
    "        net_loss.append(loss)\n",
    "        \n",
    "        loss_visualizer.plot(fake_discriminator_loss, real_discriminator_loss, generator_loss)\n",
    "        # Display progress\n",
    "        t.set_description('Train batch %i' % i)\n",
    "        t.set_postfix(loss=loss, step=step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = './puma.jpg' # random.choice(test_image_paths)\n",
    "\n",
    "rgb = io.imread(path)\n",
    "rgb = resize(rgb, output_shape=(224, 224, 3))\n",
    "image_gray = load_img(path, grayscale=True, target_size=(224, 224))\n",
    "lab = color.rgb2lab(rgb)\n",
    "\n",
    "inp = np.zeros((224, 224, 3))\n",
    "inp[:,:,0] = image_gray - greyscale_image_mean\n",
    "inp[:,:,1] = image_gray - greyscale_image_mean\n",
    "inp[:,:,2] = image_gray - greyscale_image_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "out = colorizer.predict(np.array([inp]), batch_size=1)[0]\n",
    "\n",
    "img = np.zeros((224, 224, 3))\n",
    "img[...,0] = lab[...,0]\n",
    "img[...,1:] = out\n",
    "\n",
    "plt.imshow(color.lab2rgb(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
