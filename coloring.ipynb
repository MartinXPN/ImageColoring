{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, color\n",
    "from skimage.transform import resize\n",
    "\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "from slice import Slice\n",
    "from colorizer import create_colorizer\n",
    "from discriminator import create_discriminator\n",
    "from batch_generators import DiscriminatorRealGenerator, ColorizerBatchGenerator, DiscriminatorFakeGenerator\n",
    "from visualizers import LossVisualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_trainable(layers, is_trainable):\n",
    "    for l in layers:\n",
    "        l.trainable = is_trainable\n",
    "        \n",
    "def create_GAN(generator, discriminator):\n",
    "    generator_trainable_layers = [layer for layer in generator.layers if layer.trainable]\n",
    "    discriminator_trainable_layers = [layer for layer in discriminator.layers if layer.trainable]\n",
    "\n",
    "    network_input = Input(shape=(224, 224, 3))\n",
    "    generator_output = generator(network_input)\n",
    "\n",
    "    lightness = Slice(slice(0, 1), axis=3) (network_input)\n",
    "    lab = concatenate([lightness, generator_output])\n",
    "    network_output = discriminator(lab)\n",
    "\n",
    "    GAN = Model(network_input, network_output)\n",
    "    return GAN, generator_trainable_layers, discriminator_trainable_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "colorizer, vgg = create_colorizer()\n",
    "discriminator = create_discriminator()\n",
    "gan, generator_trainable_layers, discriminator_trainable_layers = create_GAN(colorizer, discriminator)\n",
    "\n",
    "discriminator.compile( loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.01, nesterov=True) )\n",
    "gan.compile(           loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.01, nesterov=True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define paths for train / validation / test datasets\n",
    "train_root = '../coco/train2014/'\n",
    "valid_root = '../coco/val2014/'\n",
    "test_root = '../coco/test2014/'\n",
    "\n",
    "train_image_paths = [train_root + item for item in os.listdir(train_root) if item.endswith('.jpg') ]\n",
    "valid_image_paths = [valid_root + item for item in os.listdir(valid_root) if item.endswith('.jpg') ]\n",
    "test_image_paths  = [test_root  + item for item in os.listdir(test_root)  if item.endswith('.jpg') ]\n",
    "\n",
    "print( 'Train:', len(train_image_paths) )\n",
    "print( 'Validation:', len(valid_image_paths) )\n",
    "print( 'Test:', len(test_image_paths) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 37\n",
    "\n",
    "# Train data generators\n",
    "discriminator_real_generator = DiscriminatorRealGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "discriminator_fake_generator = DiscriminatorFakeGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "colorizer_generator = ColorizerBatchGenerator(image_paths=train_image_paths, batch_size=batch_size, image_height=224, image_width=224)\n",
    "\n",
    "print('There are', len(train_image_paths) / batch_size, 'steps per one train epoch for one complete cycle')\n",
    "print('There are', len(valid_image_paths) / batch_size, 'steps per one validation epoch for one complete cycle')\n",
    "\n",
    "checkpoint_path=\"../checkpoints/model-{epoch:03d}-{loss:.4f}.model\"\n",
    "model_saver = ModelCheckpoint(filepath=checkpoint_path, monitor='loss', save_best_only=True, mode='min')\n",
    "# tensorboard = TensorBoard(log_dir='/tmp/coloring/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load models\n",
    "discriminator = load_model('../checkpoints/discriminator-3.model')\n",
    "colorizer = load_model('../checkpoints/colorizer-3.model')\n",
    "gan = load_model('../checkpoints/gan-3.model', custom_objects={'Slice': Slice})\n",
    "\n",
    "discriminator.compile( loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.01, nesterov=True) )\n",
    "gan.compile(           loss='binary_crossentropy', optimizer=SGD(lr=0.01, momentum=0.01, nesterov=True) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "%matplotlib notebook\n",
    "\n",
    "\n",
    "fake_discriminator_loss = []\n",
    "real_discriminator_loss = []\n",
    "generator_loss = []\n",
    "pattern = [0, 1, 2, 1, 2, 1, 2, 1]\n",
    "\n",
    "epochs = 2\n",
    "steps_per_epoch = 500\n",
    "validation_steps = 33\n",
    "# callbacks = [tensorboard, model_saver]\n",
    "\n",
    "\n",
    "for epoch in range(1, epochs):\n",
    "    \n",
    "    steps = pattern * ( steps_per_epoch / len(pattern) )\n",
    "    t = tqdm( range(len(steps)) )\n",
    "    loss_visualizer = LossVisualizer()\n",
    "\n",
    "    for i in t:\n",
    "        step = steps[i]\n",
    "        \n",
    "        # Make discriminator better on predicting real images\n",
    "        if step == 0:\n",
    "            net = discriminator                                   # Propagate the data only through discriminator\n",
    "            make_trainable(discriminator_trainable_layers, True)  # make discriminator layers trainable\n",
    "            make_trainable(generator_trainable_layers, False)     # we don't touch the generator\n",
    "            batch_generator = discriminator_real_generator        # Images are real\n",
    "            net_loss = real_discriminator_loss\n",
    "                \n",
    "        # Make discriminator better on detecting fake images\n",
    "        elif step == 1:\n",
    "            net = gan                                             # Propagate the data though the whole gan\n",
    "            make_trainable(discriminator_trainable_layers, True)  # Train the discriminator\n",
    "            make_trainable(generator_trainable_layers, False)     # But don't touch the generator as it's not his turn\n",
    "            batch_generator = discriminator_fake_generator        # Images are fake\n",
    "            net_loss = fake_discriminator_loss\n",
    "        \n",
    "        # Make colorizer better in fooling the discriminator\n",
    "        else:\n",
    "            net = gan                                             # Propagate the data through the whole gan\n",
    "            make_trainable(discriminator_trainable_layers, False) # Don't train the discriminator when fooling it\n",
    "            make_trainable(generator_trainable_layers, True)      # Train only the generator\n",
    "            batch_generator = colorizer_generator                 # Lets fool the discriminator\n",
    "            net_loss = generator_loss\n",
    "\n",
    "            \n",
    "        # Train on the current batch\n",
    "        batch = batch_generator.next()\n",
    "        x, y = batch\n",
    "        loss = net.train_on_batch(x, y)\n",
    "        net_loss.append(loss)\n",
    "        \n",
    "        if i % len(pattern) == 0:\n",
    "            loss_visualizer.plot(fake_discriminator_loss, real_discriminator_loss, generator_loss)\n",
    "        # Display progress\n",
    "        t.set_description('Train batch %i' % i)\n",
    "        t.set_postfix(loss=loss, step=step)\n",
    "    \n",
    "    # Save model checkpoints\n",
    "    gan.save('../checkpoints/gan-' + str(epoch) + '.model')\n",
    "    colorizer.save('../checkpoints/colorizer-' + str(epoch) + '.model')\n",
    "    discriminator.save('../checkpoints/discriminator-' + str(epoch) + '.model')\n",
    "    \n",
    "    # Clear loss lists to prepare for the next epoch\n",
    "    del fake_discriminator_loss[:]\n",
    "    del real_discriminator_loss[:]\n",
    "    del generator_loss[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "path = './puma.jpg'                                          # random.choice(test_image_paths)\n",
    "inp, _ = colorizer_generator.generate_one(path)              # get input for generator\n",
    "\n",
    "out = colorizer.predict(np.array([inp]), batch_size=1)[0]    # make a prediction and get a,b channels scaled to (-1;1)\n",
    "\n",
    "rgb = resize( io.imread(path), output_shape=(224, 224, 3) )  # resize the image to display it later on\n",
    "img = np.zeros((224, 224, 3))                                # image that we are displaying has 224x224 size\n",
    "img[...,0] = color.rgb2lab(rgb)[...,0]                       # first channel is the lightness of the image\n",
    "img[...,1:] = out * 128.                                     # a,b channels are scaled to [-128;128]\n",
    "\n",
    "print(out.shape)\n",
    "plt.imshow(color.lab2rgb(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(out)):\n",
    "    for j in out[i]:\n",
    "        if j[0] != j[1]:\n",
    "            print( j[0], j[1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[77][23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
