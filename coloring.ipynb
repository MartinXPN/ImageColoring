{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import threading\n",
    "\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv2D, Deconvolution2D\n",
    "from keras.layers import MaxPooling2D, UpSampling2D\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "from keras.layers import GlobalMaxPooling2D\n",
    "from keras.layers import merge, concatenate, add\n",
    "from keras.engine.topology import get_source_inputs\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.preprocessing import image as image_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from imagenet_utils import _obtain_input_shape\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "\n",
    "WEIGHTS_PATH = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "WEIGHTS_PATH_NO_TOP = 'https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_model(input_tensor=None, input_shape=None):\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=48,\n",
    "                                      data_format=K.image_data_format(),\n",
    "                                      include_top=False)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        inputs = Input(shape=input_shape)\n",
    "    else:\n",
    "        if not K.is_keras_tensor(input_tensor):\n",
    "            inputs = Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            inputs = input_tensor\n",
    "    \n",
    "    # Encoder 1\n",
    "    e1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(inputs)\n",
    "    e1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(e1)\n",
    "    e1 = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(e1)\n",
    "\n",
    "    # Encoder 2\n",
    "    e2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(e1)\n",
    "    e2 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(e2)\n",
    "    e2 = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(e2)\n",
    "\n",
    "    # Encoder 3\n",
    "    e3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(e2)\n",
    "    e3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(e3)\n",
    "    e3 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(e3)\n",
    "    e3 = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(e3)\n",
    "\n",
    "    # Encoder 4\n",
    "    e4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(e3)\n",
    "    e4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(e4)\n",
    "    e4 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(e4)\n",
    "    e4 = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(e4)\n",
    "\n",
    "    # Encoder 5\n",
    "    e5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(e4)\n",
    "    e5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(e5)\n",
    "    e5 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(e5)\n",
    "    e5 = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(e5)\n",
    "    \n",
    "    # Now lets decode the representation\n",
    "    # Using residual connections (in this case concatenate)\n",
    "    \n",
    "    # Decoder 5\n",
    "    d5 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv1')(e5)\n",
    "    d5 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv2')(d5)\n",
    "    d5 = Deconvolution2D(512, (3, 3), activation='relu', padding='same', name='block5_deconv3')(d5)\n",
    "    d5 = UpSampling2D((2, 2), name='block5_upsample')(d5)\n",
    "    \n",
    "    # Decoder 4\n",
    "    merged = concatenate([d5, e4])\n",
    "    d4 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv1')(merged)\n",
    "    d4 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv2')(d4)\n",
    "    d4 = Deconvolution2D(256, (3, 3), activation='relu', padding='same', name='block4_deconv3')(d4)\n",
    "    d4 = UpSampling2D((2, 2), name='block4_upsample')(d4)\n",
    "    \n",
    "    # Decoder 3\n",
    "    merged = concatenate([d4, e3])\n",
    "    d3 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv1')(merged)\n",
    "    d3 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv2')(d3)\n",
    "    d3 = Deconvolution2D(128, (3, 3), activation='relu', padding='same', name='block3_deconv3')(d3)\n",
    "    d3 = UpSampling2D((2, 2), name='block3_upsample')(d3)\n",
    "    \n",
    "    # Decoder 2\n",
    "    merged = concatenate([d3, e2])\n",
    "    d2 = Deconvolution2D(64, (3, 3), activation='relu', padding='same', name='block2_deconv1')(merged)\n",
    "    d2 = Deconvolution2D(64, (3, 3), activation='relu', padding='same', name='block2_deconv2')(d2)\n",
    "    d2 = UpSampling2D((2, 2), name='block2_upsample')(d2)\n",
    "    \n",
    "    # Decoder 1\n",
    "    merged = concatenate([d2, e1])\n",
    "    d1 = Deconvolution2D(32, (3, 3), activation='relu', padding='same', name='block1_deconv1')(merged)\n",
    "    d1 = Deconvolution2D(32, (3, 3), activation='relu', padding='same', name='block1_deconv2')(d1)\n",
    "    d1 = UpSampling2D((2, 2), name='block1_upsample')(d1)\n",
    "    \n",
    "    d0 = Conv2D(16, (3, 3), activation='relu',    padding='same', name='out1')(d1)\n",
    "    d0 = Conv2D(3, (3, 3), activation='sigmoid', padding='same', name='out2')(d0)\n",
    "\n",
    "\n",
    "    \n",
    "    # Create model.\n",
    "    vgg16 = Model(inputs, e5, name='vgg16')\n",
    "    weights_path = get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                            WEIGHTS_PATH_NO_TOP,\n",
    "                            cache_subdir='models')\n",
    "    \n",
    "    # Load weights of vgg16 and fix them (set non-trainable)\n",
    "    vgg16.load_weights(weights_path)\n",
    "    for l in vgg16.layers:\n",
    "        l.trainable = False\n",
    "    \n",
    "    model = Model(inputs, d0, name='colorizer')\n",
    "    print( model.summary() )\n",
    "    return model, vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model, vgg = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img = load_img('./Shifen-Waterfall-Taiwan.jpg', target_size=(224, 224))\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "# res_first = first.predict([x], 1, verbose=1)\n",
    "res_second = model.predict([x], 1, verbose=1)\n",
    "\n",
    "# print(res_first[0].shape)\n",
    "print(res_second[0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='kullback_leibler_divergence',\n",
    "              optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BatchGenerator:\n",
    "\n",
    "    def __init__(self, image_paths, batch_size, image_height, image_width):\n",
    "        self.image_paths = image_paths\n",
    "        self.batch_size = batch_size\n",
    "        self.image_height = image_height\n",
    "        self.image_width = image_width\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        with self.lock:\n",
    "            batch_features = np.zeros((self.batch_size, self.image_height, self.image_width, 3))\n",
    "            batch_labels   = np.zeros((self.batch_size, self.image_height, self.image_width, 3))\n",
    "\n",
    "            for i in range(self.batch_size):\n",
    "                path= random.choice(self.image_paths)\n",
    "                batch_features[i] = load_img(path, target_size=(self.image_height, self.image_width))\n",
    "                batch_labels[i] = load_img(path, target_size=(self.image_height, self.image_width))\n",
    "            return batch_features, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_root = './test2014/'\n",
    "image_paths = [train_root + item for item in os.listdir(train_root) if item.endswith('.jpg') ]\n",
    "print(image_paths[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "steps_per_epoch = len(image_paths) / batch_size\n",
    "print( steps_per_epoch, 'iterations per one epoch' )\n",
    "print( 'There are', len(image_paths), 'images in total' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit_generator(BatchGenerator(image_paths=image_paths, \n",
    "                              batch_size=batch_size, \n",
    "                              image_height=224,\n",
    "                              image_width=224), \n",
    "                    steps_per_epoch = steps_per_epoch, \n",
    "                    epochs = 1,\n",
    "                    callbacks=[TensorBoard(log_dir='/tmp/coloring')], \n",
    "                    verbose=1, \n",
    "                    workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
